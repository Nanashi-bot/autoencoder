{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLFIosktd6fNZOGSjkSe7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nanashi-bot/autoencoder/blob/main/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZEyAwZamYroF"
      },
      "outputs": [],
      "source": [
        "# Initial data preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "Eyfn4hGXtqUC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 572\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channels = 3, num_classes = 1):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Encoders\n",
        "        self.encoder1 = self.encoder_block(input_channels, 64)\n",
        "        self.encoder2 = self.encoder_block(64, 128)\n",
        "        self.encoder3 = self.encoder_block(128, 256)\n",
        "        self.encoder4 = self.encoder_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Decoders\n",
        "        self.decoder1 = self.decoder_block(1024, 512, 256)\n",
        "        self.decoder2 = self.decoder_block(512, 256, 128)\n",
        "        self.decoder3 = self.decoder_block(256, 128, 64)\n",
        "\n",
        "        # Output Layer\n",
        "        self.output = self.output_block(128,64,32)\n",
        "\n",
        "\n",
        "    def encoder_block(self, in_channels, num_filters):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, num_filters, kernel_size=3, padding=0),  # Convolution with 3x3 filter\n",
        "            nn.ReLU(inplace=True),                                          # ReLU activation\n",
        "            nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=0),  # Convolution with 3x3 filter\n",
        "            nn.ReLU(inplace=True),                                          # ReLU activation\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2)                           # Max Pooling with 2x2 filter\n",
        "            )\n",
        "\n",
        "    def decoder_block(self, in_channels, num_filters, output_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, num_filters, kernel_size=3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(num_filters, output_channels, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def output_block(self, in_channels, num_filters, output_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, out_channels=1, kernel_size=1),\n",
        "            nn.Sigmoid()   # Use softmax for multiclass, sigmoid for binary\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"Input shape:\", x.shape)\n",
        "        # Encoders\n",
        "        s1 = self.encoder1(x)           # Gives first encoder output to be passed to d4\n",
        "        # print(\"First encoding done, s1 shape:\",s1.shape)\n",
        "        s2 = self.encoder2(F.max_pool2d(s1, kernel_size=2, stride=2)) # Gives second encoder output to be passed to d3\n",
        "        # print(\"Second encoding done, s2 shape:\",s2.shape)\n",
        "        s3 = self.encoder3(F.max_pool2d(s2, kernel_size=2, stride=2))  # Gives third encoder output to be passed to d2\n",
        "        # print(\"Third encoding done, s3 shape:\",s3.shape)\n",
        "        s4 = self.encoder4(F.max_pool2d(s3, kernel_size=2, stride=2))  # Gives fourth encoder output to be passed to d1\n",
        "        # print(\"Fourth encoding done, s4 shape:\",s4.shape)\n",
        "        # Bottleneck\n",
        "        b1 = self.bottleneck(F.max_pool2d(s4, kernel_size=2, stride=2))\n",
        "        # print(\"Bottleneck passed, shape:\",b1.shape)\n",
        "\n",
        "\n",
        "        # Decoders\n",
        "        d1 = b1\n",
        "        # print(\"First downsampling, output shape:\",d1.shape)\n",
        "        resize_transform1 = transforms.Resize((56, 56))\n",
        "        s4 = resize_transform1(s4)\n",
        "        # print(\"Shape of s4:\",s4.shape)\n",
        "        d1 = torch.cat([d1, s4], dim=1)\n",
        "        # print(\"After concatenating\",d1.shape)\n",
        "        d2 = self.decoder1(d1)\n",
        "        # print(\"First decoding done, d2 shape:\",d2.shape)\n",
        "\n",
        "        resize_transform2 = transforms.Resize((104, 104))\n",
        "        s3 = resize_transform2(s3)\n",
        "        # print(\"Shape of s3:\",s3.shape)\n",
        "        d2 = torch.cat([d2, s3], dim=1)\n",
        "        # print(\"After concatenating, d2 shape:\",d2.shape)\n",
        "        d3 = self.decoder2(d2)\n",
        "        # print(\"Second decoding done, output shape:\",d3.shape)\n",
        "\n",
        "        resize_transform3 = transforms.Resize((200, 200))\n",
        "        s2 = resize_transform3(s2)\n",
        "        # print(\"Shape of s2:\",s2.shape)\n",
        "        d3 = torch.cat([d3, s2], dim=1)\n",
        "        # print(\"After concatenating, d3 shape:\",d3.shape)\n",
        "        d4 = self.decoder3(d3)\n",
        "        # print(\"Third decoding done, d4 shape:\",d4.shape)\n",
        "\n",
        "        resize_transform4 = transforms.Resize((392, 392))\n",
        "        s1 = resize_transform4(s1)\n",
        "        # print(\"Shape of s1:\",s1.shape)\n",
        "        d4 = torch.cat([d4, s1], dim=1)\n",
        "        print(\"After concatenating, d4 shape:\",d4.shape)\n",
        "\n",
        "        # Output\n",
        "        outputs = self.output(d4)\n",
        "        print(\"Output shape:\",output.shape)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "YpH_UFG6tuvw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 572, 572)\n",
        "model = UNet()\n",
        "output = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrx7emrML4KB",
        "outputId": "8c97b4ad-f6c4-455e-d7d9-33fd6d3710a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After concatenating, d4 shape: torch.Size([1, 128, 392, 392])\n",
            "Output shape: torch.Size([1, 2, 388, 388])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE FOLLOWING THIS IS FOR TEST PURPOSES"
      ],
      "metadata": {
        "id": "U8oxrBjooiqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up_conv = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
        "\n",
        "input_tensor = torch.randn(1, 1024, 28, 28)\n",
        "normal_conv = nn.Conv2d(512, 512, kernel_size=3, padding=0)\n",
        "output_tensor = up_conv(input_tensor)\n",
        "print(output_tensor.shape)\n",
        "v = normal_conv(output_tensor)\n",
        "print(v.shape)"
      ],
      "metadata": {
        "id": "Uw9nBXpgLhvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "image = torch.randn(1, 3, 64, 64)\n",
        "resize_transform = transforms.Resize((56, 56))\n",
        "resized_image = resize_transform(image)\n",
        "\n",
        "print(f\"Resized shape: {resized_image.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jBL48CvSTF-",
        "outputId": "5419569f-fc53-40f6-81ab-4a26f01c4538"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized shape: torch.Size([1, 3, 56, 56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.randn(1, 128, 392, 392)\n",
        "conv1 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "\n",
        "output1 = conv1(input_tensor)\n",
        "print(f\"Shape after first conv: {output1.shape}\")\n",
        "\n",
        "output2 = conv2(output1)\n",
        "print(f\"Shape after second conv: {output2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xae6_QQYYDYu",
        "outputId": "c6a41470-dcbd-4909-eb55-114e40528561"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after first conv: torch.Size([1, 64, 390, 390])\n",
            "Shape after second conv: torch.Size([1, 64, 388, 388])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUV8PgYhm2CE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}